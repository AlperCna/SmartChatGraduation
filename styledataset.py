import pandas as pd
from datasets import load_dataset
import random
import sys


def create_dataset_by_label():
    print("ğŸš€ Veri seti oluÅŸturuluyor (Tweet-PN Etiketli)...\n")

    final_data = []

    # 1. FORMAL VERÄ° (WikiANN - Wikipedia) - AYNI KALDI
    print("1ï¸âƒ£ Formal Veriler (Wikipedia) indiriliyor...")
    try:
        ds_formal = load_dataset("wikiann", "tr", split="train", streaming=True)
        count = 0
        for item in ds_formal:
            text = " ".join(item['tokens']).replace(" .", ".").replace(" ,", ",")
            if 40 < len(text) < 250:
                final_data.append({'text': text, 'label': 'formal'})
                count += 1
                if count % 100 == 0:
                    sys.stdout.write(f"\r   â³ Formal: {count}/1000")
                    sys.stdout.flush()
            if count == 1000: break
        print(f"\n   âœ… Formal veri tamam.")
    except Exception as e:
        print(f"   âŒ Formal hata: {e}")

    # 2. INFORMAL VERÄ° (Winvoker - SADECE 'tweet-pn' OLANLAR)
    print("\n2ï¸âƒ£ Informal Veriler (Winvoker: tweet-pn) taranÄ±yor...")
    try:
        # Winvoker veri setini yÃ¼klÃ¼yoruz
        ds_informal = load_dataset("winvoker/turkish-sentiment-analysis-dataset", split="train", streaming=True)

        count = 0
        for item in ds_informal:
            # Ekran gÃ¶rÃ¼ntÃ¼sÃ¼ndeki "tweet-pn" etiketini 'dataset' sÃ¼tununda arÄ±yoruz.
            # EÄŸer item iÃ§inde 'dataset' sÃ¼tunu varsa ve deÄŸeri 'tweet-pn' ise alÄ±yoruz.
            source_label = item.get('dataset', '')

            if source_label == 'tweet-pn':
                text = item['text'].replace('\n', ' ').strip()

                # Yine de Ã§ok kÄ±sa (tek kelime) veya Ã§ok uzun olanlarÄ± eleyelim
                if 15 < len(text) < 280:
                    final_data.append({'text': text, 'label': 'informal'})
                    count += 1

                    if count % 100 == 0:
                        sys.stdout.write(f"\r   â³ Informal: {count}/1000")
                        sys.stdout.flush()

            if count == 1000: break

        if count < 1000:
            print(f"\n   âš ï¸ UyarÄ±: Sadece {count} adet tweet-pn bulundu. (Streaming modunda az gelmiÅŸ olabilir)")
        else:
            print(f"\n   âœ… Informal veri (tweet-pn) tamam.")

    except Exception as e:
        print(f"   âŒ Informal hata: {e}")


    # 3. NEUTRAL VERÄ° (OPUS-100) - AYNI KALDI
    print("\n3ï¸âƒ£ Neutral Veriler (Kitap/AltyazÄ±) indiriliyor...")
    try:
        ds_neutral = load_dataset("opus100", "en-tr", split="train", streaming=True)
        count = 0
        for item in ds_neutral:
            tr_text = item['translation']['tr'].replace('\n', ' ').strip()
            if 25 < len(tr_text) < 100:
                clean_text = tr_text.replace('"', '').replace("'", "")
                final_data.append({'text': clean_text, 'label': 'neutral'})
                count += 1
            if count == 1000: break
        print(f"   âœ… Neutral veri tamam.")
    except Exception as e:
        print(f"   âŒ Neutral hata: {e}")


    # KAYDETME

    if final_data:
        df = pd.DataFrame(final_data)
        df = df.sample(frac=1, random_state=42).reset_index(drop=True)

        print("\nğŸ“Š VERÄ° DAÄILIMI:")
        print(df['label'].value_counts())

        filename = "StyleApapterDataset.csv"
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"\nâœ… Dosya '{filename}' olarak kaydedildi. Tam istediÄŸin gibi tweet-pn verileri alÄ±ndÄ±!")
    else:
        print("\nâŒ Veri toplanamadÄ±.")


if __name__ == "__main__":
    create_dataset_by_label()